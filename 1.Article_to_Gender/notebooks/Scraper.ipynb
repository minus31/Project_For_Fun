{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import re \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_links(page):\n",
    "\n",
    "    res = requests.get(page)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "    linkByAges = {}\n",
    "\n",
    "    for age in [20, 30, 40, 50]:\n",
    "        item_age = soup.select_one(r\".item_age.item_{}s\".format(age))\n",
    "        \n",
    "        if not item_age:\n",
    "            continue\n",
    "\n",
    "        female_links = [item[\"href\"] for item in item_age.select_one('.rank_female').select(\"a\")]\n",
    "        male_links = [item[\"href\"] for item in item_age.select_one('.rank_male').select(\"a\")]\n",
    "\n",
    "        linkByAges[age] = [female_links, male_links]\n",
    "\n",
    "    return linkByAges\n",
    "\n",
    "def contentsInArticle(link):\n",
    "    res = requests.get(link)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    try :\n",
    "        title = soup.select_one(\"h3\").text.strip()\n",
    "    except : \n",
    "        title = \"None\"\n",
    "        \n",
    "    try: \n",
    "        content = soup.select_one(\"section\").text.strip()\n",
    "    except :\n",
    "        content = \"None\"\n",
    "    \n",
    "    return title, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "title = []\n",
    "body = []\n",
    "age_sex = []\n",
    "\n",
    "start_day = datetime.datetime.now()# - datetime.timedelta(days=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date : 20190423 started\n",
      "date : 20190423 done \n",
      "\n",
      "date : 20190422 started\n",
      "date : 20190422 done \n",
      "\n",
      "date : 20190421 started\n",
      "date : 20190421 done \n",
      "\n",
      "date : 20190420 started\n",
      "date : 20190420 done \n",
      "\n",
      "date : 20190419 started\n",
      "date : 20190419 done \n",
      "\n",
      "date : 20190418 started\n",
      "date : 20190418 done \n",
      "\n",
      "date : 20190417 started\n",
      "date : 20190417 done \n",
      "\n",
      "date : 20190416 started\n",
      "date : 20190416 done \n",
      "\n",
      "date : 20190415 started\n",
      "date : 20190415 done \n",
      "\n",
      "date : 20190414 started\n",
      "date : 20190414 done \n",
      "\n",
      "date : 20190413 started\n",
      "date : 20190413 done \n",
      "\n",
      "date : 20190412 started\n",
      "date : 20190412 done \n",
      "\n",
      "date : 20190411 started\n",
      "date : 20190411 done \n",
      "\n",
      "date : 20190410 started\n",
      "date : 20190410 done \n",
      "\n",
      "date : 20190409 started\n",
      "date : 20190409 done \n",
      "\n",
      "date : 20190408 started\n",
      "date : 20190408 done \n",
      "\n",
      "date : 20190407 started\n",
      "date : 20190407 done \n",
      "\n",
      "date : 20190406 started\n",
      "date : 20190406 done \n",
      "\n",
      "date : 20190405 started\n",
      "date : 20190405 done \n",
      "\n",
      "date : 20190404 started\n",
      "date : 20190404 done \n",
      "\n",
      "date : 20190403 started\n",
      "date : 20190403 done \n",
      "\n",
      "date : 20190402 started\n",
      "date : 20190402 done \n",
      "\n",
      "date : 20190401 started\n",
      "date : 20190401 done \n",
      "\n",
      "date : 20190331 started\n",
      "date : 20190331 done \n",
      "\n",
      "date : 20190330 started\n",
      "date : 20190330 done \n",
      "\n",
      "date : 20190329 started\n",
      "date : 20190329 done \n",
      "\n",
      "date : 20190328 started\n",
      "date : 20190328 done \n",
      "\n",
      "date : 20190327 started\n",
      "date : 20190327 done \n",
      "\n",
      "date : 20190326 started\n",
      "date : 20190326 done \n",
      "\n",
      "date : 20190325 started\n",
      "date : 20190325 done \n",
      "\n",
      "date : 20190324 started\n",
      "date : 20190324 done \n",
      "\n",
      "date : 20190323 started\n",
      "date : 20190323 done \n",
      "\n",
      "date : 20190322 started\n",
      "date : 20190322 done \n",
      "\n",
      "date : 20190321 started\n",
      "date : 20190321 done \n",
      "\n",
      "date : 20190320 started\n",
      "date : 20190320 done \n",
      "\n",
      "date : 20190319 started\n",
      "date : 20190319 done \n",
      "\n",
      "date : 20190318 started\n",
      "date : 20190318 done \n",
      "\n",
      "date : 20190317 started\n",
      "date : 20190317 done \n",
      "\n",
      "date : 20190316 started\n",
      "date : 20190316 done \n",
      "\n",
      "date : 20190315 started\n",
      "date : 20190315 done \n",
      "\n",
      "date : 20190314 started\n",
      "date : 20190314 done \n",
      "\n",
      "date : 20190313 started\n",
      "date : 20190313 done \n",
      "\n",
      "date : 20190312 started\n",
      "date : 20190312 done \n",
      "\n",
      "date : 20190311 started\n",
      "date : 20190311 done \n",
      "\n",
      "date : 20190310 started\n",
      "date : 20190310 done \n",
      "\n",
      "date : 20190309 started\n",
      "date : 20190309 done \n",
      "\n",
      "date : 20190308 started\n",
      "date : 20190308 done \n",
      "\n",
      "date : 20190307 started\n",
      "date : 20190307 done \n",
      "\n",
      "date : 20190306 started\n",
      "date : 20190306 done \n",
      "\n",
      "date : 20190305 started\n",
      "date : 20190305 done \n",
      "\n",
      "date : 20190304 started\n",
      "date : 20190304 done \n",
      "\n",
      "date : 20190303 started\n",
      "date : 20190303 done \n",
      "\n",
      "date : 20190302 started\n",
      "date : 20190302 done \n",
      "\n",
      "date : 20190301 started\n",
      "date : 20190301 done \n",
      "\n",
      "date : 20190228 started\n",
      "date : 20190228 done \n",
      "\n",
      "date : 20190227 started\n",
      "date : 20190227 done \n",
      "\n",
      "date : 20190226 started\n",
      "date : 20190226 done \n",
      "\n",
      "date : 20190225 started\n",
      "date : 20190225 done \n",
      "\n",
      "date : 20190224 started\n",
      "date : 20190224 done \n",
      "\n",
      "date : 20190223 started\n",
      "date : 20190223 done \n",
      "\n",
      "date : 20190222 started\n",
      "date : 20190222 done \n",
      "\n",
      "date : 20190221 started\n",
      "date : 20190221 done \n",
      "\n",
      "date : 20190220 started\n",
      "date : 20190220 done \n",
      "\n",
      "date : 20190219 started\n",
      "date : 20190219 done \n",
      "\n",
      "date : 20190218 started\n",
      "date : 20190218 done \n",
      "\n",
      "date : 20190217 started\n",
      "date : 20190217 done \n",
      "\n",
      "date : 20190216 started\n",
      "date : 20190216 done \n",
      "\n",
      "date : 20190215 started\n",
      "date : 20190215 done \n",
      "\n",
      "date : 20190214 started\n",
      "date : 20190214 done \n",
      "\n",
      "date : 20190213 started\n",
      "date : 20190213 done \n",
      "\n",
      "date : 20190212 started\n",
      "date : 20190212 done \n",
      "\n",
      "date : 20190211 started\n",
      "date : 20190211 done \n",
      "\n",
      "date : 20190210 started\n",
      "date : 20190210 done \n",
      "\n",
      "date : 20190209 started\n",
      "date : 20190209 done \n",
      "\n",
      "date : 20190208 started\n",
      "date : 20190208 done \n",
      "\n",
      "date : 20190207 started\n",
      "date : 20190207 done \n",
      "\n",
      "date : 20190206 started\n",
      "date : 20190206 done \n",
      "\n",
      "date : 20190205 started\n",
      "date : 20190205 done \n",
      "\n",
      "date : 20190204 started\n",
      "date : 20190204 done \n",
      "\n",
      "date : 20190203 started\n",
      "date : 20190203 done \n",
      "\n",
      "date : 20190202 started\n",
      "date : 20190202 done \n",
      "\n",
      "date : 20190201 started\n",
      "date : 20190201 done \n",
      "\n",
      "date : 20190131 started\n",
      "date : 20190131 done \n",
      "\n",
      "date : 20190130 started\n",
      "date : 20190130 done \n",
      "\n",
      "date : 20190129 started\n",
      "date : 20190129 done \n",
      "\n",
      "date : 20190128 started\n",
      "date : 20190128 done \n",
      "\n",
      "date : 20190127 started\n",
      "date : 20190127 done \n",
      "\n",
      "date : 20190126 started\n",
      "date : 20190126 done \n",
      "\n",
      "date : 20190125 started\n",
      "date : 20190125 done \n",
      "\n",
      "date : 20190124 started\n",
      "date : 20190124 done \n",
      "\n",
      "date : 20190123 started\n",
      "date : 20190123 done \n",
      "\n",
      "date : 20190122 started\n",
      "date : 20190122 done \n",
      "\n",
      "date : 20190121 started\n",
      "date : 20190121 done \n",
      "\n",
      "date : 20190120 started\n",
      "date : 20190120 done \n",
      "\n",
      "date : 20190119 started\n",
      "date : 20190119 done \n",
      "\n",
      "date : 20190118 started\n",
      "date : 20190118 done \n",
      "\n",
      "date : 20190117 started\n",
      "date : 20190117 done \n",
      "\n",
      "date : 20190116 started\n",
      "date : 20190116 done \n",
      "\n",
      "date : 20190115 started\n",
      "date : 20190115 done \n",
      "\n",
      "date : 20190114 started\n",
      "date : 20190114 done \n",
      "\n",
      "date : 20190113 started\n",
      "date : 20190113 done \n",
      "\n",
      "date : 20190112 started\n",
      "date : 20190112 done \n",
      "\n",
      "date : 20190111 started\n",
      "date : 20190111 done \n",
      "\n",
      "date : 20190110 started\n",
      "date : 20190110 done \n",
      "\n",
      "date : 20190109 started\n",
      "date : 20190109 done \n",
      "\n",
      "date : 20190108 started\n",
      "date : 20190108 done \n",
      "\n",
      "date : 20190107 started\n",
      "date : 20190107 done \n",
      "\n",
      "date : 20190106 started\n",
      "date : 20190106 done \n",
      "\n",
      "date : 20190105 started\n",
      "date : 20190105 done \n",
      "\n",
      "date : 20190104 started\n",
      "date : 20190104 done \n",
      "\n",
      "date : 20190103 started\n",
      "date : 20190103 done \n",
      "\n",
      "date : 20190102 started\n",
      "date : 20190102 done \n",
      "\n",
      "date : 20190101 started\n",
      "date : 20190101 done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(113): \n",
    "    \n",
    "    date = start_day - datetime.timedelta(days=i)\n",
    "    date = date.strftime('%Y%m%d')\n",
    "    \n",
    "    page = \"https://media.daum.net/ranking/age/?regDate={}\".format(date)\n",
    "    \n",
    "    print(\"date : {} started\".format(date))    \n",
    "    # Links for the day by ages and sex\n",
    "    elements = []\n",
    "    \n",
    "    linkByAges = items_links(page)\n",
    "    \n",
    "    for age in linkByAges.keys():\n",
    "        \n",
    "        female = linkByAges[age][0]\n",
    "        male = linkByAges[age][1]\n",
    "        \n",
    "        female_elem = [contentsInArticle(link) for link in female]\n",
    "        male_elem = [contentsInArticle(link) for link in male]\n",
    "        \n",
    "        for fe in female_elem:\n",
    "            \"\"\"fe : [title, body]\"\"\"\n",
    "            \n",
    "            dates.append(date)\n",
    "            title.append(fe[0])\n",
    "            body.append(fe[1])\n",
    "            age_sex.append(str(age) + \"&\" + \"female\")\n",
    "            \n",
    "            \n",
    "        for ma in male_elem:\n",
    "            \n",
    "            dates.append(date)\n",
    "            title.append(ma[0])\n",
    "            body.append(ma[1])\n",
    "            age_sex.append(str(age) + \"&\" + \"male\")\n",
    "\n",
    "    print(\"date : {} done \\n\".format(date))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>age_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6150</th>\n",
       "      <td>20190101</td>\n",
       "      <td>\"세수했나 문잠궜나\".. 편리함과 바꾼 기억력, 당신도 '영츠하이머'?</td>\n",
       "      <td>대학생 강모(25)씨는 최근 건망증이 너무 심해져 벌써 치매가 온 건 아닌지 걱정이...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6151</th>\n",
       "      <td>20190101</td>\n",
       "      <td>중년여성의 화병, 비흡연 폐암 원인 중 하나일까?</td>\n",
       "      <td>[사진=Magic mine/shutterstock]\\n          \\n\\n화,...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6152</th>\n",
       "      <td>20190101</td>\n",
       "      <td>한진家 이명희 또 기소.. 이번엔 '갑질 폭행' 혐의</td>\n",
       "      <td>[서울신문]조양호 한진그룹 회장의 부인 이명희 전 일우재단 이사장이 운전기사와 직원...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6153</th>\n",
       "      <td>20190101</td>\n",
       "      <td>4월부터 저소득노인 기초연금 '25만→30만원'..선정기준 확대</td>\n",
       "      <td>【서울=뉴시스】전신 기자 = 3일 서울 종로구 경복궁역에서 빈곤노인기초연금보장연대가...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6154</th>\n",
       "      <td>20190101</td>\n",
       "      <td>안 올라가던 팔이 올라가네..신통한 어깨 마사지법</td>\n",
       "      <td>━\\n          [더,오래] 유재욱의 심야병원(35)\\n          \\...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6155</th>\n",
       "      <td>20190101</td>\n",
       "      <td>[이상한 소비]②\"제주도 가느니 동남아\"..만족해야 돈 쓴다</td>\n",
       "      <td>[편집자주] 소비가 이상하다. 마트는 장사가 안되는데 백화점은 호황을 누리고 있다....</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6156</th>\n",
       "      <td>20190101</td>\n",
       "      <td>김정은 신년사 요지..'비핵화 재천명·조건없는 개성공단 재개'</td>\n",
       "      <td>(서울=연합뉴스) 정빛나 기자 = 김정은 북한 노동당 위원장은 1일 올해 신년사를 ...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6157</th>\n",
       "      <td>20190101</td>\n",
       "      <td>한국, 모바일 인터넷 속도 후진국?..카타르보다 뒤져</td>\n",
       "      <td>(지디넷코리아=백봉삼 기자)세계 모바일, 광대역 인터넷 속도를 비교한 분석 보고서가...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6158</th>\n",
       "      <td>20190101</td>\n",
       "      <td>오늘부터 최저임금 8350원..근로자 500만명 인상 '역대 최대'</td>\n",
       "      <td>© News1 김일환 디자이너\\n          \\n\\n(세종=뉴스1) 박정환 기...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6159</th>\n",
       "      <td>20190101</td>\n",
       "      <td>이순자 \"우리나라 민주주의 아버지는 내 남편 전두환\"</td>\n",
       "      <td>전두환 전 대통령이 제20대 국회의원선거날인 13일 오전 서울 서대문구 연희동주민센...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                    Title  \\\n",
       "6150  20190101  \"세수했나 문잠궜나\".. 편리함과 바꾼 기억력, 당신도 '영츠하이머'?   \n",
       "6151  20190101              중년여성의 화병, 비흡연 폐암 원인 중 하나일까?   \n",
       "6152  20190101            한진家 이명희 또 기소.. 이번엔 '갑질 폭행' 혐의   \n",
       "6153  20190101      4월부터 저소득노인 기초연금 '25만→30만원'..선정기준 확대   \n",
       "6154  20190101              안 올라가던 팔이 올라가네..신통한 어깨 마사지법   \n",
       "6155  20190101        [이상한 소비]②\"제주도 가느니 동남아\"..만족해야 돈 쓴다   \n",
       "6156  20190101       김정은 신년사 요지..'비핵화 재천명·조건없는 개성공단 재개'   \n",
       "6157  20190101            한국, 모바일 인터넷 속도 후진국?..카타르보다 뒤져   \n",
       "6158  20190101    오늘부터 최저임금 8350원..근로자 500만명 인상 '역대 최대'   \n",
       "6159  20190101            이순자 \"우리나라 민주주의 아버지는 내 남편 전두환\"   \n",
       "\n",
       "                                                   Body    age_sex  \n",
       "6150  대학생 강모(25)씨는 최근 건망증이 너무 심해져 벌써 치매가 온 건 아닌지 걱정이...  50&female  \n",
       "6151  [사진=Magic mine/shutterstock]\\n          \\n\\n화,...  50&female  \n",
       "6152  [서울신문]조양호 한진그룹 회장의 부인 이명희 전 일우재단 이사장이 운전기사와 직원...  50&female  \n",
       "6153  【서울=뉴시스】전신 기자 = 3일 서울 종로구 경복궁역에서 빈곤노인기초연금보장연대가...  50&female  \n",
       "6154  ━\\n          [더,오래] 유재욱의 심야병원(35)\\n          \\...  50&female  \n",
       "6155  [편집자주] 소비가 이상하다. 마트는 장사가 안되는데 백화점은 호황을 누리고 있다....    50&male  \n",
       "6156  (서울=연합뉴스) 정빛나 기자 = 김정은 북한 노동당 위원장은 1일 올해 신년사를 ...    50&male  \n",
       "6157  (지디넷코리아=백봉삼 기자)세계 모바일, 광대역 인터넷 속도를 비교한 분석 보고서가...    50&male  \n",
       "6158  © News1 김일환 디자이너\\n          \\n\\n(세종=뉴스1) 박정환 기...    50&male  \n",
       "6159  전두환 전 대통령이 제20대 국회의원선거날인 13일 오전 서울 서대문구 연희동주민센...    50&male  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = pd.DataFrame(columns=[\"date\", \"Title\", \"Body\", \"age_sex\"])\n",
    "results = pd.DataFrame({\"date\": dates, \"Title\" : title, \"Body\" : body, \"age_sex\" : age_sex})\n",
    "results.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"../Data/article_201904.bin\", \"wb\") as f :\n",
    "    \n",
    "    pickle.dump(results, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
