{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "import re \n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def items_links(page):\n",
    "\n",
    "    res = requests.get(page)\n",
    "    soup = BeautifulSoup(res.content, \"html.parser\")\n",
    "\n",
    "    linkByAges = {}\n",
    "\n",
    "    for age in [20, 30, 40, 50]:\n",
    "        item_age = soup.select_one(r\".item_age.item_{}s\".format(age))\n",
    "        \n",
    "        if not item_age:\n",
    "            continue\n",
    "\n",
    "        female_links = [item[\"href\"] for item in item_age.select_one('.rank_female').select(\"a\")]\n",
    "        male_links = [item[\"href\"] for item in item_age.select_one('.rank_male').select(\"a\")]\n",
    "\n",
    "        linkByAges[age] = [female_links, male_links]\n",
    "\n",
    "    return linkByAges\n",
    "\n",
    "def contentsInArticle(link):\n",
    "    res = requests.get(link)\n",
    "    soup = BeautifulSoup(res.content, 'html.parser')\n",
    "    try :\n",
    "        title = soup.select_one(\"h3\").text.strip()\n",
    "    except : \n",
    "        title = \"None\"\n",
    "        \n",
    "    try: \n",
    "        content = soup.select_one(\"section\").text.strip()\n",
    "    except :\n",
    "        content = \"None\"\n",
    "    \n",
    "    return title, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = []\n",
    "title = []\n",
    "body = []\n",
    "age_sex = []\n",
    "\n",
    "start_day = datetime.datetime.now()# - datetime.timedelta(days=113)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date : 20191017 started\n",
      "date : 20191017 done \n",
      "\n",
      "date : 20191016 started\n",
      "date : 20191016 done \n",
      "\n",
      "date : 20191015 started\n",
      "date : 20191015 done \n",
      "\n",
      "date : 20191014 started\n",
      "date : 20191014 done \n",
      "\n",
      "date : 20191013 started\n",
      "date : 20191013 done \n",
      "\n",
      "date : 20191012 started\n",
      "date : 20191012 done \n",
      "\n",
      "date : 20191011 started\n",
      "date : 20191011 done \n",
      "\n",
      "date : 20191010 started\n",
      "date : 20191010 done \n",
      "\n",
      "date : 20191009 started\n",
      "date : 20191009 done \n",
      "\n",
      "date : 20191008 started\n",
      "date : 20191008 done \n",
      "\n",
      "date : 20191007 started\n",
      "date : 20191007 done \n",
      "\n",
      "date : 20191006 started\n",
      "date : 20191006 done \n",
      "\n",
      "date : 20191005 started\n",
      "date : 20191005 done \n",
      "\n",
      "date : 20191004 started\n",
      "date : 20191004 done \n",
      "\n",
      "date : 20191003 started\n",
      "date : 20191003 done \n",
      "\n",
      "date : 20191002 started\n",
      "date : 20191002 done \n",
      "\n",
      "date : 20191001 started\n",
      "date : 20191001 done \n",
      "\n",
      "date : 20190930 started\n",
      "date : 20190930 done \n",
      "\n",
      "date : 20190929 started\n",
      "date : 20190929 done \n",
      "\n",
      "date : 20190928 started\n",
      "date : 20190928 done \n",
      "\n",
      "date : 20190927 started\n",
      "date : 20190927 done \n",
      "\n",
      "date : 20190926 started\n",
      "date : 20190926 done \n",
      "\n",
      "date : 20190925 started\n",
      "date : 20190925 done \n",
      "\n",
      "date : 20190924 started\n",
      "date : 20190924 done \n",
      "\n",
      "date : 20190923 started\n",
      "date : 20190923 done \n",
      "\n",
      "date : 20190922 started\n",
      "date : 20190922 done \n",
      "\n",
      "date : 20190921 started\n",
      "date : 20190921 done \n",
      "\n",
      "date : 20190920 started\n",
      "date : 20190920 done \n",
      "\n",
      "date : 20190919 started\n",
      "date : 20190919 done \n",
      "\n",
      "date : 20190918 started\n",
      "date : 20190918 done \n",
      "\n",
      "date : 20190917 started\n",
      "date : 20190917 done \n",
      "\n",
      "date : 20190916 started\n",
      "date : 20190916 done \n",
      "\n",
      "date : 20190915 started\n",
      "date : 20190915 done \n",
      "\n",
      "date : 20190914 started\n",
      "date : 20190914 done \n",
      "\n",
      "date : 20190913 started\n",
      "date : 20190913 done \n",
      "\n",
      "date : 20190912 started\n",
      "date : 20190912 done \n",
      "\n",
      "date : 20190911 started\n",
      "date : 20190911 done \n",
      "\n",
      "date : 20190910 started\n",
      "date : 20190910 done \n",
      "\n",
      "date : 20190909 started\n",
      "date : 20190909 done \n",
      "\n",
      "date : 20190908 started\n",
      "date : 20190908 done \n",
      "\n",
      "date : 20190907 started\n",
      "date : 20190907 done \n",
      "\n",
      "date : 20190906 started\n",
      "date : 20190906 done \n",
      "\n",
      "date : 20190905 started\n",
      "date : 20190905 done \n",
      "\n",
      "date : 20190904 started\n",
      "date : 20190904 done \n",
      "\n",
      "date : 20190903 started\n",
      "date : 20190903 done \n",
      "\n",
      "date : 20190902 started\n",
      "date : 20190902 done \n",
      "\n",
      "date : 20190901 started\n",
      "date : 20190901 done \n",
      "\n",
      "date : 20190831 started\n",
      "date : 20190831 done \n",
      "\n",
      "date : 20190830 started\n",
      "date : 20190830 done \n",
      "\n",
      "date : 20190829 started\n",
      "date : 20190829 done \n",
      "\n",
      "date : 20190828 started\n",
      "date : 20190828 done \n",
      "\n",
      "date : 20190827 started\n",
      "date : 20190827 done \n",
      "\n",
      "date : 20190826 started\n",
      "date : 20190826 done \n",
      "\n",
      "date : 20190825 started\n",
      "date : 20190825 done \n",
      "\n",
      "date : 20190824 started\n",
      "date : 20190824 done \n",
      "\n",
      "date : 20190823 started\n",
      "date : 20190823 done \n",
      "\n",
      "date : 20190822 started\n",
      "date : 20190822 done \n",
      "\n",
      "date : 20190821 started\n",
      "date : 20190821 done \n",
      "\n",
      "date : 20190820 started\n",
      "date : 20190820 done \n",
      "\n",
      "date : 20190819 started\n",
      "date : 20190819 done \n",
      "\n",
      "date : 20190818 started\n",
      "date : 20190818 done \n",
      "\n",
      "date : 20190817 started\n",
      "date : 20190817 done \n",
      "\n",
      "date : 20190816 started\n",
      "date : 20190816 done \n",
      "\n",
      "date : 20190815 started\n",
      "date : 20190815 done \n",
      "\n",
      "date : 20190814 started\n",
      "date : 20190814 done \n",
      "\n",
      "date : 20190813 started\n",
      "date : 20190813 done \n",
      "\n",
      "date : 20190812 started\n",
      "date : 20190812 done \n",
      "\n",
      "date : 20190811 started\n",
      "date : 20190811 done \n",
      "\n",
      "date : 20190810 started\n",
      "date : 20190810 done \n",
      "\n",
      "date : 20190809 started\n",
      "date : 20190809 done \n",
      "\n",
      "date : 20190808 started\n",
      "date : 20190808 done \n",
      "\n",
      "date : 20190807 started\n",
      "date : 20190807 done \n",
      "\n",
      "date : 20190806 started\n",
      "date : 20190806 done \n",
      "\n",
      "date : 20190805 started\n",
      "date : 20190805 done \n",
      "\n",
      "date : 20190804 started\n",
      "date : 20190804 done \n",
      "\n",
      "date : 20190803 started\n",
      "date : 20190803 done \n",
      "\n",
      "date : 20190802 started\n",
      "date : 20190802 done \n",
      "\n",
      "date : 20190801 started\n",
      "date : 20190801 done \n",
      "\n",
      "date : 20190731 started\n",
      "date : 20190731 done \n",
      "\n",
      "date : 20190730 started\n",
      "date : 20190730 done \n",
      "\n",
      "date : 20190729 started\n",
      "date : 20190729 done \n",
      "\n",
      "date : 20190728 started\n",
      "date : 20190728 done \n",
      "\n",
      "date : 20190727 started\n",
      "date : 20190727 done \n",
      "\n",
      "date : 20190726 started\n",
      "date : 20190726 done \n",
      "\n",
      "date : 20190725 started\n",
      "date : 20190725 done \n",
      "\n",
      "date : 20190724 started\n",
      "date : 20190724 done \n",
      "\n",
      "date : 20190723 started\n",
      "date : 20190723 done \n",
      "\n",
      "date : 20190722 started\n",
      "date : 20190722 done \n",
      "\n",
      "date : 20190721 started\n",
      "date : 20190721 done \n",
      "\n",
      "date : 20190720 started\n",
      "date : 20190720 done \n",
      "\n",
      "date : 20190719 started\n",
      "date : 20190719 done \n",
      "\n",
      "date : 20190718 started\n",
      "date : 20190718 done \n",
      "\n",
      "date : 20190717 started\n",
      "date : 20190717 done \n",
      "\n",
      "date : 20190716 started\n",
      "date : 20190716 done \n",
      "\n",
      "date : 20190715 started\n",
      "date : 20190715 done \n",
      "\n",
      "date : 20190714 started\n",
      "date : 20190714 done \n",
      "\n",
      "date : 20190713 started\n",
      "date : 20190713 done \n",
      "\n",
      "date : 20190712 started\n",
      "date : 20190712 done \n",
      "\n",
      "date : 20190711 started\n",
      "date : 20190711 done \n",
      "\n",
      "date : 20190710 started\n",
      "date : 20190710 done \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(365): \n",
    "    \n",
    "    date = start_day - datetime.timedelta(days=i)\n",
    "    date = date.strftime('%Y%m%d')\n",
    "    \n",
    "    page = \"https://media.daum.net/ranking/age/?regDate={}\".format(date)\n",
    "    \n",
    "    print(\"date : {} started\".format(date))    \n",
    "    # Links for the day by ages and sex\n",
    "    elements = []\n",
    "    \n",
    "    linkByAges = items_links(page)\n",
    "    \n",
    "    for age in linkByAges.keys():\n",
    "        \n",
    "        female = linkByAges[age][0]\n",
    "        male = linkByAges[age][1]\n",
    "        \n",
    "        female_elem = [contentsInArticle(link) for link in female]\n",
    "        male_elem = [contentsInArticle(link) for link in male]\n",
    "        \n",
    "        for fe in female_elem:\n",
    "            \"\"\"fe : [title, body]\"\"\"\n",
    "            \n",
    "            dates.append(date)\n",
    "            title.append(fe[0])\n",
    "            body.append(fe[1])\n",
    "            age_sex.append(str(age) + \"&\" + \"female\")\n",
    "            \n",
    "            \n",
    "        for ma in male_elem:\n",
    "            \n",
    "            dates.append(date)\n",
    "            title.append(ma[0])\n",
    "            body.append(ma[1])\n",
    "            age_sex.append(str(age) + \"&\" + \"male\")\n",
    "\n",
    "    print(\"date : {} done \\n\".format(date))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>age_sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3990</th>\n",
       "      <td>20190710</td>\n",
       "      <td>고유정 눈물vs현 남편 분노..의붓아들 죽음, 결국 대질조사</td>\n",
       "      <td>\"고유정이 아들을 죽였다\"고 검찰에 고소한 현남편과 고유정. [중앙포토]\\n    ...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3991</th>\n",
       "      <td>20190710</td>\n",
       "      <td>80대 노인, 50대 아들 둔기로 살해하고 음독..병원이송(종합)</td>\n",
       "      <td>범죄 수사 (PG) [정연주 제작] 일러스트\\n          \\n\\n(광주=연합...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3992</th>\n",
       "      <td>20190710</td>\n",
       "      <td>\"천사같던 반려견 수목장했는데..\" 장례업체의 '배째라' 영업</td>\n",
       "      <td>경기도 시흥의 한 무허가 장례업체에서 수목장된 반려동물들. 이 반려동물들은 업체의 ...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3993</th>\n",
       "      <td>20190710</td>\n",
       "      <td>[르포]텅텅 빈 보신탕집, 손님 꽉 찬 마라탕집..확 달라진 초복 풍경(종합)</td>\n",
       "      <td>동대문역 인근 한 보신탕집은 최근 메뉴를 변경하고 보신탕 판매를 중단했다.\\n   ...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3994</th>\n",
       "      <td>20190710</td>\n",
       "      <td>언론단체 \"SBS, 김성준 전 앵커 사표수리는 꼬리자르기 불과\" 비판</td>\n",
       "      <td>김성준 전 SBS 앵커. 방송화면 갈무리.\\n          \\n\\n&lt;에스비에스&gt;...</td>\n",
       "      <td>50&amp;female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>20190710</td>\n",
       "      <td>위증으로 역전된 '윤석열 검증'..한국·바른미래 공조 카드는</td>\n",
       "      <td>윤석열 검찰총장 후보자가 8일 국회에서 열린 국회 인사청문회에서 선서를 하고 있다....</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>20190710</td>\n",
       "      <td>고승덕 부부, 이촌파출소 건물도 사들여..용산구 매입 부담 커져</td>\n",
       "      <td>서울 용산구 이촌파출소 [연합뉴스 자료 사진]\\n          \\n\\n(서울=연...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>20190710</td>\n",
       "      <td>박지원 \"조국, 법무장관 100% 기용될 것..윤석열, 임명돼야\"</td>\n",
       "      <td>【서울=뉴시스】 박영태 기자 = 8일 오전 서울 여의도 국회에서 열린 검찰총장후보자...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>20190710</td>\n",
       "      <td>\"트럼프가 놔두겠나\"..日 '횡포' 일주일, 초조감 속 낙관론도</td>\n",
       "      <td>\"트럼프가 놔두겠나\"…日 '횡포' 일주일, 초조감 속 낙관론도 (CG) [연합뉴스T...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>20190710</td>\n",
       "      <td>가공할 '포토레지스트'..삼성 경쟁 대만업체 6500억 날려</td>\n",
       "      <td>대만의 반도체 파운드리(위탁생산) 업체 TSMC 공장 전경(TSMC 제공) © Ne...</td>\n",
       "      <td>50&amp;male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                        Title  \\\n",
       "3990  20190710            고유정 눈물vs현 남편 분노..의붓아들 죽음, 결국 대질조사   \n",
       "3991  20190710         80대 노인, 50대 아들 둔기로 살해하고 음독..병원이송(종합)   \n",
       "3992  20190710           \"천사같던 반려견 수목장했는데..\" 장례업체의 '배째라' 영업   \n",
       "3993  20190710  [르포]텅텅 빈 보신탕집, 손님 꽉 찬 마라탕집..확 달라진 초복 풍경(종합)   \n",
       "3994  20190710       언론단체 \"SBS, 김성준 전 앵커 사표수리는 꼬리자르기 불과\" 비판   \n",
       "3995  20190710            위증으로 역전된 '윤석열 검증'..한국·바른미래 공조 카드는   \n",
       "3996  20190710          고승덕 부부, 이촌파출소 건물도 사들여..용산구 매입 부담 커져   \n",
       "3997  20190710         박지원 \"조국, 법무장관 100% 기용될 것..윤석열, 임명돼야\"   \n",
       "3998  20190710          \"트럼프가 놔두겠나\"..日 '횡포' 일주일, 초조감 속 낙관론도   \n",
       "3999  20190710            가공할 '포토레지스트'..삼성 경쟁 대만업체 6500억 날려   \n",
       "\n",
       "                                                   Body    age_sex  \n",
       "3990  \"고유정이 아들을 죽였다\"고 검찰에 고소한 현남편과 고유정. [중앙포토]\\n    ...  50&female  \n",
       "3991  범죄 수사 (PG) [정연주 제작] 일러스트\\n          \\n\\n(광주=연합...  50&female  \n",
       "3992  경기도 시흥의 한 무허가 장례업체에서 수목장된 반려동물들. 이 반려동물들은 업체의 ...  50&female  \n",
       "3993  동대문역 인근 한 보신탕집은 최근 메뉴를 변경하고 보신탕 판매를 중단했다.\\n   ...  50&female  \n",
       "3994  김성준 전 SBS 앵커. 방송화면 갈무리.\\n          \\n\\n<에스비에스>...  50&female  \n",
       "3995  윤석열 검찰총장 후보자가 8일 국회에서 열린 국회 인사청문회에서 선서를 하고 있다....    50&male  \n",
       "3996  서울 용산구 이촌파출소 [연합뉴스 자료 사진]\\n          \\n\\n(서울=연...    50&male  \n",
       "3997  【서울=뉴시스】 박영태 기자 = 8일 오전 서울 여의도 국회에서 열린 검찰총장후보자...    50&male  \n",
       "3998  \"트럼프가 놔두겠나\"…日 '횡포' 일주일, 초조감 속 낙관론도 (CG) [연합뉴스T...    50&male  \n",
       "3999  대만의 반도체 파운드리(위탁생산) 업체 TSMC 공장 전경(TSMC 제공) © Ne...    50&male  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results = pd.DataFrame(columns=[\"date\", \"Title\", \"Body\", \"age_sex\"])\n",
    "results = pd.DataFrame({\"date\": dates, \"Title\" : title, \"Body\" : body, \"age_sex\" : age_sex})\n",
    "results.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "\n",
    "with open(\"./article_202001.bin\", \"wb\") as f :\n",
    "    \n",
    "    pickle.dump(results, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
